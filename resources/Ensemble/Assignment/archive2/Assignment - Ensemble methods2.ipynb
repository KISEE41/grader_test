{"cells":[{"cell_type":"markdown","metadata":{"id":"2PO8PExZwsGd"},"source":["# AirBnB guest arrival prediction using tree-based methods\n","\n","\n","\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[TOTAL POINTS: 10]\u003c/div\u003e\u003c/b\u003e\n","\n","The assignment is divided into three different levels: Level1, Level2, and Level3.\n","\n","## Learning Objective(Level 1)\n","\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 4]\u003c/div\u003e\u003c/b\u003e\n","\n","By the end of this assignment, a student should be able to\n","\n","- Apply necessary preprocessing steps on the data to make it suitable for training.\n","\n","- Train Bagging Classifier, Random Forest Classifier, XGBoost Classifier.\n","\n","- Fine-tune and monitor the performance of XGBoost.\n","\n","\n","\n","Let's start with the problem description of level1.\n","In this assignment, you will train different ensemble models to predict whether the customer will cancel the booking or not. For a tourism-based country like Nepal, hospitality is a major source of income. The given data represents booking information made by foreign customers via AirBnB for the year 2018. Your task in level1 is to use this data to predict whether the customer will cancel the booking or not.\n"]},{"cell_type":"markdown","metadata":{"id":"Epa9-UlFwsGi"},"source":["## Dataset Description:\n","\n","The dataset, **AirBnB customer arrival prediction**, contains information regarding booking in the hotel, and includes features like such as meal, arrival date(date of booking), car parking space in hotel, etc. All features are listed below.\n","\n","Note: The given dataset is a modification of [Hotel booking demand datasets](https://www.sciencedirect.com/science/article/pii/S2352340918315191) collected by **Nuano et al.** and is availabe under [Creative Commons 4.0](https://creativecommons.org/licenses/by/4.0/).\n","\n","**Number of Instances:** 119,386 \\\n","**Number of Attributes:** 25 **Input Features** + 1 **Target**(__is_canceled__)\n","\n","### Attribute Information:\n","The detail information of each attribute is listed as:\n","\n","* **hotel** - Type of hotel resort or city\n","* **is_canceled** - The label column. This indicates whether the guests canceled their booking or they checked-in\n","* **lead_time** - Number of days that elapsed between the entering date of the booking into the PMS and the arrival date\n","* **arrival_date_year** - year of the arrival date\n","* **arrival_date_month** - Month of arrival date with 12 categories: “January” to “December” expressed in numbers. 1 indicates January, and 12 indicate December. \n","* **arrival_date_week_number** - Week number of the arrival date\n","* **arrival_date_day_of_month** - Day of the month of the arrival date\n","* **stays_in_weekend_nights** - Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel.\n","* **stays_in_week_nights** - Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n","* **meal** - Type of meal booked. \n","* **country** - Country of origin. Categories are represented in the ISO 3155–3:2013 format\n","* **market_segment** - Market segment designation. In categories, the term \"TA\" means \"Travel Agents\" and \"TO\" means \"Tour Operators\"\n","* **distribution_channel** - Booking distribution channel. The term \"TA\" means \"Travel Agents\" and \"TO\" means \"Tour Operators\"\n","* **is_repeated_guest** - Value indicating if the booking name was from a repeated guest (1) or not (0)\n","* **reserved_room_type** - Code of room type reserved. \n","* **assigned_room_type** - Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g., overbooking) or by customer request.\n","* **booking_changes** - Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n","* **deposit_type** - Indication on if the customer deposited to guarantee the booking.\n","* **agent** - ID of the travel agency that made the booking\n","* **days_in_waiting_list** - Number of days the booking was on the waiting list before it was confirmed to the customer. \n","* **customer_type** - Type of booking. One of Contract, Group, Transient, and Transient-party.\n","* **adr** - Average Daily Rate\n","* **required_car_parking_spaces** - Number of car parking spaces required by the customer.\n","* **total_of_special_requests** - Number of special requests made by the customer (e.g. twin bed or high floor)\n","* **total_guests** - Total number of guests(includes adults, children, and babies)\n","* **net_booking_cancelled** - A difference between the total number of the previous booking canceled and the previous booking not canceled before this booking. A positive value means that the customer did not cancel most of the previous booking."]},{"cell_type":"markdown","metadata":{"id":"VssZ8Kf_wsGm"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1624441323965,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"XM9q2-0ZwsGp"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","RANDOM_STATE = 7\n","np.random.seed(RANDOM_STATE)"]},{"cell_type":"markdown","metadata":{"id":"pEDgsWu_wsG5"},"source":["### Load csv file"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"executionInfo":{"elapsed":1456,"status":"ok","timestamp":1624441325418,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"_ELsyzGxwsG7","outputId":"50e8f50c-17c9-4fbd-de4e-f47a4959cb8b","scrolled":false},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ehotel\u003c/th\u003e\n","      \u003cth\u003eis_canceled\u003c/th\u003e\n","      \u003cth\u003elead_time\u003c/th\u003e\n","      \u003cth\u003earrival_date_year\u003c/th\u003e\n","      \u003cth\u003earrival_date_month\u003c/th\u003e\n","      \u003cth\u003earrival_date_week_number\u003c/th\u003e\n","      \u003cth\u003earrival_date_day_of_month\u003c/th\u003e\n","      \u003cth\u003estays_in_weekend_nights\u003c/th\u003e\n","      \u003cth\u003estays_in_week_nights\u003c/th\u003e\n","      \u003cth\u003emeal\u003c/th\u003e\n","      \u003cth\u003ecountry\u003c/th\u003e\n","      \u003cth\u003emarket_segment\u003c/th\u003e\n","      \u003cth\u003edistribution_channel\u003c/th\u003e\n","      \u003cth\u003eis_repeated_guest\u003c/th\u003e\n","      \u003cth\u003ereserved_room_type\u003c/th\u003e\n","      \u003cth\u003eassigned_room_type\u003c/th\u003e\n","      \u003cth\u003ebooking_changes\u003c/th\u003e\n","      \u003cth\u003edeposit_type\u003c/th\u003e\n","      \u003cth\u003eagent\u003c/th\u003e\n","      \u003cth\u003edays_in_waiting_list\u003c/th\u003e\n","      \u003cth\u003ecustomer_type\u003c/th\u003e\n","      \u003cth\u003eadr\u003c/th\u003e\n","      \u003cth\u003erequired_car_parking_spaces\u003c/th\u003e\n","      \u003cth\u003etotal_of_special_requests\u003c/th\u003e\n","      \u003cth\u003etotal_guests\u003c/th\u003e\n","      \u003cth\u003enet_booking_cancelled\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e342\u003c/td\u003e\n","      \u003ctd\u003e2015\u003c/td\u003e\n","      \u003ctd\u003eJuly\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003ePRT\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e737\u003c/td\u003e\n","      \u003ctd\u003e2015\u003c/td\u003e\n","      \u003ctd\u003eJuly\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBB\u003c/td\u003e\n","      \u003ctd\u003ePRT\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e2015\u003c/td\u003e\n","      \u003ctd\u003eJuly\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003eBB\u003c/td\u003e\n","      \u003ctd\u003eGBR\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e75.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e13\u003c/td\u003e\n","      \u003ctd\u003e2015\u003c/td\u003e\n","      \u003ctd\u003eJuly\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003eGBR\u003c/td\u003e\n","      \u003ctd\u003eCorporate\u003c/td\u003e\n","      \u003ctd\u003eNaN\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003e304.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e75.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e14\u003c/td\u003e\n","      \u003ctd\u003e2015\u003c/td\u003e\n","      \u003ctd\u003eJuly\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003eBB\u003c/td\u003e\n","      \u003ctd\u003eGBR\u003c/td\u003e\n","      \u003ctd\u003eOnline TA\u003c/td\u003e\n","      \u003ctd\u003eTA/TO\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003e240.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e98.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["          hotel  is_canceled  ...  total_guests  net_booking_cancelled\n","0  Resort Hotel            0  ...           2.0                      0\n","1  Resort Hotel            0  ...           2.0                      0\n","2  Resort Hotel            0  ...           1.0                      0\n","3  Resort Hotel            0  ...           1.0                      0\n","4  Resort Hotel            0  ...           2.0                      0\n","\n","[5 rows x 26 columns]"]},"execution_count":2,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df= pd.read_csv(\"https://storage.googleapis.com/codehub-data/1-lv2-3-airbnb-guest-arrival.csv\", index_col = 0)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"-PYR9djVwsHG"},"source":["## Preprocessing\n","### Identification of features with missing values\n","Let's find out if the columns in our dataset has any misssing values."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1624441325421,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"Rkd1RjvSwsHI","outputId":"431fc2a3-2a22-4344-ad66-2715058775b3","scrolled":false},"outputs":[{"data":{"text/plain":["hotel                              0\n","is_canceled                        0\n","lead_time                          0\n","arrival_date_year                  0\n","arrival_date_month                 0\n","arrival_date_week_number           0\n","arrival_date_day_of_month          0\n","stays_in_weekend_nights            0\n","stays_in_week_nights               0\n","meal                           11939\n","country                          488\n","market_segment                     0\n","distribution_channel           11939\n","is_repeated_guest                  0\n","reserved_room_type                 0\n","assigned_room_type             11939\n","booking_changes                    0\n","deposit_type                       0\n","agent                          16340\n","days_in_waiting_list               0\n","customer_type                      0\n","adr                                0\n","required_car_parking_spaces        0\n","total_of_special_requests          0\n","total_guests                       4\n","net_booking_cancelled              0\n","dtype: int64"]},"execution_count":3,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"oY3mhFEOwsHQ"},"source":["We can see that columns `agent`, `assigned_room_type`, `distribution_channel`, `meal`, `country`, and `total_guests` have missing values.\n","\n","Since only four instances in the column `total_guests` have missing value, we will drop them."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1624441325423,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"UKdOTd4BwsHS"},"outputs":[],"source":["# removing all rows that have missing values in total_guests column\n","df.dropna(how='any', subset=['total_guests'], inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"85mnhFDXwsHb"},"source":["We will impute rest of the features with mode."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1624441325425,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"WVSifF4qwsHc"},"outputs":[],"source":["missing_features = ['agent', 'assigned_room_type', 'distribution_channel', 'meal', 'country']\n","for feature in missing_features:\n","    df[feature].fillna(df[feature].mode()[0], inplace = True)"]},{"cell_type":"markdown","metadata":{"id":"RQEJ1XRCwsHl"},"source":["Until now, we have imputed all the missing values in the dataset."]},{"cell_type":"markdown","metadata":{"id":"LYANbhhZwsHm"},"source":["### Feature generation\n","\n","Here we will combine features `arrival_date_month` and `arrival_date_year` to generate a new feature `month`."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1567,"status":"ok","timestamp":1624441326968,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"AeWZtrUJwsHn","outputId":"cf96fe80-bbd8-4708-da8e-71d534d8b9e6"},"outputs":[{"data":{"text/plain":["array([2015, 2016, 2017])"]},"execution_count":6,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df['arrival_date_year'].unique()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1624441326969,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"_ZXwBZH7wsHu","outputId":"368b9939-0062-4540-f99f-6d126534ad17","scrolled":true},"outputs":[{"data":{"text/plain":["array(['July', 'August', 'September', 'October', 'November', 'December',\n","       'January', 'February', 'March', 'April', 'May', 'June'],\n","      dtype=object)"]},"execution_count":7,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df['arrival_date_month'].unique()"]},{"cell_type":"markdown","metadata":{"id":"dIPIGG8LwsH1"},"source":["In the feature `month`,  we will consider Jan, 2015 as 0, Feb, 2015 as 1, and so on. So this feature will represent the month number starting from Jan, 2015."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1624441326970,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"beVp5g3ZwsH2"},"outputs":[],"source":["replace_year = {2015:0, 2016: 12, 2017:24}\n","replace_month= {'Januray':0, 'February': 1, 'March': 2, 'April': 3, 'May': 4, 'June': 5, 'July': 6, 'August': 7, 'September': 8, 'October': 9, 'November': 10, 'December': 11}"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1624441326971,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"L3Q3b4atwsH9","outputId":"53880e97-55ee-45c4-810d-ed8331550041","scrolled":true},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ehotel\u003c/th\u003e\n","      \u003cth\u003eis_canceled\u003c/th\u003e\n","      \u003cth\u003elead_time\u003c/th\u003e\n","      \u003cth\u003earrival_date_year\u003c/th\u003e\n","      \u003cth\u003earrival_date_month\u003c/th\u003e\n","      \u003cth\u003earrival_date_week_number\u003c/th\u003e\n","      \u003cth\u003earrival_date_day_of_month\u003c/th\u003e\n","      \u003cth\u003estays_in_weekend_nights\u003c/th\u003e\n","      \u003cth\u003estays_in_week_nights\u003c/th\u003e\n","      \u003cth\u003emeal\u003c/th\u003e\n","      \u003cth\u003ecountry\u003c/th\u003e\n","      \u003cth\u003emarket_segment\u003c/th\u003e\n","      \u003cth\u003edistribution_channel\u003c/th\u003e\n","      \u003cth\u003eis_repeated_guest\u003c/th\u003e\n","      \u003cth\u003ereserved_room_type\u003c/th\u003e\n","      \u003cth\u003eassigned_room_type\u003c/th\u003e\n","      \u003cth\u003ebooking_changes\u003c/th\u003e\n","      \u003cth\u003edeposit_type\u003c/th\u003e\n","      \u003cth\u003eagent\u003c/th\u003e\n","      \u003cth\u003edays_in_waiting_list\u003c/th\u003e\n","      \u003cth\u003ecustomer_type\u003c/th\u003e\n","      \u003cth\u003eadr\u003c/th\u003e\n","      \u003cth\u003erequired_car_parking_spaces\u003c/th\u003e\n","      \u003cth\u003etotal_of_special_requests\u003c/th\u003e\n","      \u003cth\u003etotal_guests\u003c/th\u003e\n","      \u003cth\u003enet_booking_cancelled\u003c/th\u003e\n","      \u003cth\u003emonth\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e342\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBB\u003c/td\u003e\n","      \u003ctd\u003ePRT\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003e9.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e737\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eBB\u003c/td\u003e\n","      \u003ctd\u003ePRT\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003e9.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003eBB\u003c/td\u003e\n","      \u003ctd\u003eGBR\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003eDirect\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eC\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003e9.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e75.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e13\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003eBB\u003c/td\u003e\n","      \u003ctd\u003eGBR\u003c/td\u003e\n","      \u003ctd\u003eCorporate\u003c/td\u003e\n","      \u003ctd\u003eTA/TO\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003e304.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e75.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003eResort Hotel\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e14\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003eBB\u003c/td\u003e\n","      \u003ctd\u003eGBR\u003c/td\u003e\n","      \u003ctd\u003eOnline TA\u003c/td\u003e\n","      \u003ctd\u003eTA/TO\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003eA\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eNo Deposit\u003c/td\u003e\n","      \u003ctd\u003e240.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003eTransient\u003c/td\u003e\n","      \u003ctd\u003e98.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["          hotel  is_canceled  ...  net_booking_cancelled  month\n","0  Resort Hotel            0  ...                      0      0\n","1  Resort Hotel            0  ...                      0      0\n","2  Resort Hotel            0  ...                      0      0\n","3  Resort Hotel            0  ...                      0      0\n","4  Resort Hotel            0  ...                      0      0\n","\n","[5 rows x 27 columns]"]},"execution_count":9,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["df['arrival_date_year'] = df['arrival_date_year'].replace(replace_year)\n","df['arrival_date_month'] = df['arrival_date_month'].replace(replace_month)\n","df['month'] = df['arrival_date_year']+df['arrival_date_year']\n","# df.drop(['arrival_date_year', 'arrival_date_year'], axis = 1, inplace = True)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"-MNF119rwsIC"},"source":["### Label Encoding\n","\n","All categorical features are encoded with label encoding.\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":537,"status":"ok","timestamp":1624441327500,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"sMblbXeEwsIE","outputId":"a068a6e4-82f4-48dc-8025-002facbc4736"},"outputs":[{"data":{"text/html":["\u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003ehotel\u003c/th\u003e\n","      \u003cth\u003eis_canceled\u003c/th\u003e\n","      \u003cth\u003elead_time\u003c/th\u003e\n","      \u003cth\u003earrival_date_year\u003c/th\u003e\n","      \u003cth\u003earrival_date_month\u003c/th\u003e\n","      \u003cth\u003earrival_date_week_number\u003c/th\u003e\n","      \u003cth\u003earrival_date_day_of_month\u003c/th\u003e\n","      \u003cth\u003estays_in_weekend_nights\u003c/th\u003e\n","      \u003cth\u003estays_in_week_nights\u003c/th\u003e\n","      \u003cth\u003emeal\u003c/th\u003e\n","      \u003cth\u003ecountry\u003c/th\u003e\n","      \u003cth\u003emarket_segment\u003c/th\u003e\n","      \u003cth\u003edistribution_channel\u003c/th\u003e\n","      \u003cth\u003eis_repeated_guest\u003c/th\u003e\n","      \u003cth\u003ereserved_room_type\u003c/th\u003e\n","      \u003cth\u003eassigned_room_type\u003c/th\u003e\n","      \u003cth\u003ebooking_changes\u003c/th\u003e\n","      \u003cth\u003edeposit_type\u003c/th\u003e\n","      \u003cth\u003eagent\u003c/th\u003e\n","      \u003cth\u003edays_in_waiting_list\u003c/th\u003e\n","      \u003cth\u003ecustomer_type\u003c/th\u003e\n","      \u003cth\u003eadr\u003c/th\u003e\n","      \u003cth\u003erequired_car_parking_spaces\u003c/th\u003e\n","      \u003cth\u003etotal_of_special_requests\u003c/th\u003e\n","      \u003cth\u003etotal_guests\u003c/th\u003e\n","      \u003cth\u003enet_booking_cancelled\u003c/th\u003e\n","      \u003cth\u003emonth\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e342\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e135\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e9.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e737\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e135\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e4\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e9.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e59\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e9.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e75.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e13\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e59\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e304.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e75.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e14\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e7\u003c/td\u003e\n","      \u003ctd\u003e27\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e59\u003c/td\u003e\n","      \u003ctd\u003e6\u003c/td\u003e\n","      \u003ctd\u003e3\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e240.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e2\u003c/td\u003e\n","      \u003ctd\u003e98.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e1\u003c/td\u003e\n","      \u003ctd\u003e2.0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e"],"text/plain":["   hotel  is_canceled  lead_time  ...  total_guests  net_booking_cancelled  month\n","0      1            0        342  ...           2.0                      0      0\n","1      1            0        737  ...           2.0                      0      0\n","2      1            0          7  ...           1.0                      0      0\n","3      1            0         13  ...           1.0                      0      0\n","4      1            0         14  ...           2.0                      0      0\n","\n","[5 rows x 27 columns]"]},"execution_count":10,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","\n","cat_vars = [var for var in df.columns if df[var].dtypes=='O']\n","df[cat_vars] = df[cat_vars].astype(str).apply(LabelEncoder().fit_transform)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"3gv7QJLkwsIN"},"source":["### Train-Test Split\n","\n","Before performing train-test split let's check the class distribution."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1624441327501,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"YPhv7xg2wsIO","outputId":"faadcd21-90ac-401e-91f2-8846eaa4ca94"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7fdeca05aad0\u003e"]},"execution_count":11,"metadata":{"tags":[]},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{"tags":[]},"output_type":"display_data"}],"source":["df['is_canceled'].value_counts().plot(kind = 'bar')"]},{"cell_type":"markdown","metadata":{"id":"idp18pfRwsIW"},"source":["We see that the dataset is imbalanced. This forces us to:\n","- Set `stratify` to `y` while splitting the dataset so that the proportion of `is_canceled = 0`, and `is_canceled = 1` remains constant in the training and test dataset.\n","- Use metric like f1 score to assess the performance of our model"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1624441327502,"user":{"displayName":"Rebati Raman Gaire","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi3QZHsmMNBuaZn1sJZzP_WXehWNmeInTjQtKJh=s64","userId":"08852999111297596173"},"user_tz":-345},"id":"ioN2runWwsIX"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","\n","RANDOM_STATE = 7\n","y= df['is_canceled']\n","X = df.drop('is_canceled', axis = 1)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = RANDOM_STATE)"]},{"cell_type":"markdown","metadata":{"id":"-FH86C_ewsId"},"source":["## Bagging\n","\n","### Exercise 1: Training Bagging Classifier\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 1]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","\n","\n","**Task:** \n","-  Instantiate BaggingClassifier in the variable `bagging` with __n_estimators__ set to 100 and  __random_state__ set to RANDOM_STATE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4WnJLOCwsIe"},"outputs":[],"source":["from sklearn.ensemble import BaggingClassifier\n","from sklearn.metrics import f1_score\n","\n","\n","bagging = None\n","### BEGIN SOLUTION\n","bagging = BaggingClassifier(n_estimators = 100, random_state = RANDOM_STATE)\n","### END SOLUTION\n","bagging.fit(X_train, y_train)\n","print(\"Train f1_score:\", f1_score(y_train, bagging.predict(X_train), average = 'weighted'))\n","print(\"Test f1_score:\", f1_score(y_test, bagging.predict(X_test), average = 'weighted'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTrHUGX7wsIm"},"outputs":[],"source":["assert bagging is not None\n","### BEGIN HIDDEN TESTS\n","\n","assert bagging.n_estimators == 100, \"Please set the number of estimators to 100\"\n","assert bagging.random_state == RANDOM_STATE, \"Please set the random state to RANDOM_STATE\"\n","\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"7aoaNQUYwsIs"},"source":["## Random Forest\n","\n","### Exercise 2: Training Random Forest Classifier\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 1]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","\n","\n","**Task:** \n","-  Instantiate RandomForestClassifier in the variable `rf` with __n_estimators__ set to 100, and  __random_state__ set to RANDOM_STATE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XDrmqnkwsIt"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rf = None\n","### BEGIN SOLUTION\n","rf = RandomForestClassifier(n_estimators = 100, random_state = RANDOM_STATE)\n","### END SOLUTION\n","rf.fit(X_train, y_train)\n","print(\"Train f1_score:\", f1_score(y_train, rf.predict(X_train), average = 'weighted'))\n","print(\"Test f1_score:\", f1_score(y_test, rf.predict(X_test), average = 'weighted'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuRcc3LHwsIy"},"outputs":[],"source":["assert rf is not None\n","### BEGIN HIDDEN TESTS\n","\n","assert rf.n_estimators == 100, \"Please set the number of estimators to 100\"\n","assert rf.random_state == RANDOM_STATE, \"Please set the random state to RANDOM_STATE\"\n","\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"HrCu3Pp-wsI5"},"source":["## XGBoost\n","\n","### Exercise 3: XGBoost Training\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 1]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Here we will train XGBoost with most of the parameters left to default.\n","\n","**Task:** \n","-  Instantiate XGBClassifier in the variable `xgb` with __n_estimators__ set to 100 and __random_state__ set to RANDOM_STATE\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JTDajYP9wsI6","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["XGBClassifer with default parameters:\n","\n","XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","              colsample_bynode=1, colsample_bytree=1, gamma=0,\n","              learning_rate=0.1, max_delta_step=0, max_depth=3,\n","              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n","              nthread=None, objective='binary:logistic', random_state=7,\n","              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n","              silent=None, subsample=1, verbosity=1)\n"]}],"source":["from xgboost import XGBClassifier\n","\n","\n","xgb = None\n","### BEGIN SOLUTION\n","xgb = XGBClassifier(n_estimators = 100, random_state = RANDOM_STATE)\n","### END SOLUTION\n","xgb.fit(X_train, y_train)\n","print(\"XGBClassifer with default parameters:\\n\")\n","print(xgb)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"co-fgNlBwsI_"},"outputs":[],"source":["assert xgb is not None\n","### BEGIN HIDDEN TESTS\n","\n","assert xgb.n_estimators == 100, \"Please set the number of estimators to 100\"\n","assert xgb.random_state == RANDOM_STATE, \"Please set the random state to RANDOM_STATE\"\n","\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"2MfIlj_wwsJE"},"source":["### Model Evaluation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aAU-U1zAwsJF"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train f1_score: 0.8411529574306595\n","Test f1_score: 0.8421695275032451\n"]}],"source":["print(\"Train f1_score:\", f1_score(y_train, xgb.predict(X_train), average = 'weighted'))\n","print(\"Test f1_score:\", f1_score(y_test, xgb.predict(X_test), average = 'weighted'))"]},{"cell_type":"markdown","metadata":{"id":"Cp8cVcgkwsJL"},"source":["### Tree Visualization\n","\n","### Exercise 4: Plot the tree structure\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Plot the tree structure in the cell below. You can use `plot_tree()` or `to_graphviz()` method provided by xgboost to plot the tree.\n","\n","**Task:** \n","-  Your task is to plot the 20th tree and answer the quiz below.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"48H5N7r-wsJM","scrolled":true},"outputs":[{"data":{"image/svg+xml":"\u003c?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?\u003e\n\u003c!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"\u003e\n\u003c!-- Generated by graphviz version 2.40.1 (20161225.0304)\n --\u003e\n\u003c!-- Title: %3 Pages: 1 --\u003e\n\u003csvg width=\"1516pt\" height=\"305pt\"\n viewBox=\"0.00 0.00 1515.78 305.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\n\u003cg id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 301)\"\u003e\n\u003ctitle\u003e%3\u003c/title\u003e\n\u003cpolygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-301 1511.7843,-301 1511.7843,4 -4,4\"/\u003e\n\u003c!-- 0 --\u003e\n\u003cg id=\"node1\" class=\"node\"\u003e\n\u003ctitle\u003e0\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"729.3922\" cy=\"-279\" rx=\"59.5901\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"729.3922\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003ecountry\u0026lt;135\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 1 --\u003e\n\u003cg id=\"node2\" class=\"node\"\u003e\n\u003ctitle\u003e1\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"598.3922\" cy=\"-192\" rx=\"81.7856\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"598.3922\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003emarket_segment\u0026lt;6\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 0\u0026#45;\u0026gt;1 --\u003e\n\u003cg id=\"edge1\" class=\"edge\"\u003e\n\u003ctitle\u003e0\u0026#45;\u0026gt;1\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#0000ff\" d=\"M704.4437,-262.4312C684.1276,-248.9388 655.2304,-229.7475 632.73,-214.8045\"/\u003e\n\u003cpolygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"634.4095,-211.7184 624.1429,-209.1016 630.5368,-217.5496 634.4095,-211.7184\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"707.8922\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eyes, missing\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 2 --\u003e\n\u003cg id=\"node3\" class=\"node\"\u003e\n\u003ctitle\u003e2\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"908.3922\" cy=\"-192\" rx=\"61.99\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"908.3922\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003elead_time\u0026lt;25\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 0\u0026#45;\u0026gt;2 --\u003e\n\u003cg id=\"edge2\" class=\"edge\"\u003e\n\u003ctitle\u003e0\u0026#45;\u0026gt;2\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#ff0000\" d=\"M760.9817,-263.6464C790.5787,-249.2613 834.9826,-227.6795 867.3189,-211.963\"/\u003e\n\u003cpolygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"869.0523,-215.012 876.5163,-207.4927 865.9923,-208.7163 869.0523,-215.012\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"838.3922\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eno\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 3 --\u003e\n\u003cg id=\"node4\" class=\"node\"\u003e\n\u003ctitle\u003e3\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"278.3922\" cy=\"-105\" rx=\"81.7856\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"278.3922\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003emarket_segment\u0026lt;4\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 1\u0026#45;\u0026gt;3 --\u003e\n\u003cg id=\"edge3\" class=\"edge\"\u003e\n\u003ctitle\u003e1\u0026#45;\u0026gt;3\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#0000ff\" d=\"M546.623,-177.9253C490.1551,-162.5731 399.8288,-138.0156 339.8167,-121.6998\"/\u003e\n\u003cpolygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"340.6549,-118.3007 330.0869,-119.0545 338.8184,-125.0555 340.6549,-118.3007\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"493.8922\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eyes, missing\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 4 --\u003e\n\u003cg id=\"node5\" class=\"node\"\u003e\n\u003ctitle\u003e4\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"598.3922\" cy=\"-105\" rx=\"114.2798\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"598.3922\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003etotal_of_special_requests\u0026lt;1\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 1\u0026#45;\u0026gt;4 --\u003e\n\u003cg id=\"edge4\" class=\"edge\"\u003e\n\u003ctitle\u003e1\u0026#45;\u0026gt;4\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#ff0000\" d=\"M598.3922,-173.9735C598.3922,-162.1918 598.3922,-146.5607 598.3922,-133.1581\"/\u003e\n\u003cpolygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"601.8923,-133.0033 598.3922,-123.0034 594.8923,-133.0034 601.8923,-133.0033\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"606.3922\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eno\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 5 --\u003e\n\u003cg id=\"node10\" class=\"node\"\u003e\n\u003ctitle\u003e5\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"908.3922\" cy=\"-105\" rx=\"129.1772\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"908.3922\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003erequired_car_parking_spaces\u0026lt;1\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 2\u0026#45;\u0026gt;5 --\u003e\n\u003cg id=\"edge9\" class=\"edge\"\u003e\n\u003ctitle\u003e2\u0026#45;\u0026gt;5\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#0000ff\" d=\"M908.3922,-173.9735C908.3922,-162.1918 908.3922,-146.5607 908.3922,-133.1581\"/\u003e\n\u003cpolygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"911.8923,-133.0033 908.3922,-123.0034 904.8923,-133.0034 911.8923,-133.0033\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"943.8922\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eyes, missing\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 6 --\u003e\n\u003cg id=\"node11\" class=\"node\"\u003e\n\u003ctitle\u003e6\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"1227.3922\" cy=\"-105\" rx=\"59.5901\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"1227.3922\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003ecountry\u0026lt;139\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 2\u0026#45;\u0026gt;6 --\u003e\n\u003cg id=\"edge10\" class=\"edge\"\u003e\n\u003ctitle\u003e2\u0026#45;\u0026gt;6\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#ff0000\" d=\"M953.7583,-179.6274C1011.521,-163.874 1111.222,-136.6828 1173.0015,-119.8338\"/\u003e\n\u003cpolygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1174.2263,-123.1277 1182.953,-117.1198 1172.3844,-116.3743 1174.2263,-123.1277\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"1095.3922\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eno\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 7 --\u003e\n\u003cg id=\"node6\" class=\"node\"\u003e\n\u003ctitle\u003e7\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"88.3922\" cy=\"-18\" rx=\"88.2844\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"88.3922\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eleaf=\u0026#45;0.0696895644\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 3\u0026#45;\u0026gt;7 --\u003e\n\u003cg id=\"edge5\" class=\"edge\"\u003e\n\u003ctitle\u003e3\u0026#45;\u0026gt;7\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#0000ff\" d=\"M242.6546,-88.636C211.9332,-74.5688 167.445,-54.1979 134.1305,-38.9433\"/\u003e\n\u003cpolygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"135.1648,-35.5675 124.6154,-34.5865 132.2505,-41.932 135.1648,-35.5675\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"230.8922\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eyes, missing\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 8 --\u003e\n\u003cg id=\"node7\" class=\"node\"\u003e\n\u003ctitle\u003e8\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"278.3922\" cy=\"-18\" rx=\"83.3857\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"278.3922\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eleaf=\u0026#45;0.121095099\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 3\u0026#45;\u0026gt;8 --\u003e\n\u003cg id=\"edge6\" class=\"edge\"\u003e\n\u003ctitle\u003e3\u0026#45;\u0026gt;8\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#ff0000\" d=\"M278.3922,-86.9735C278.3922,-75.1918 278.3922,-59.5607 278.3922,-46.1581\"/\u003e\n\u003cpolygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"281.8923,-46.0033 278.3922,-36.0034 274.8923,-46.0034 281.8923,-46.0033\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"286.3922\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eno\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 9 --\u003e\n\u003cg id=\"node8\" class=\"node\"\u003e\n\u003ctitle\u003e9\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"464.3922\" cy=\"-18\" rx=\"85.2851\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"464.3922\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eleaf=0.0574659519\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 4\u0026#45;\u0026gt;9 --\u003e\n\u003cg id=\"edge7\" class=\"edge\"\u003e\n\u003ctitle\u003e4\u0026#45;\u0026gt;9\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#0000ff\" d=\"M571.2753,-87.3943C550.6163,-73.9813 522.0031,-55.4042 499.5805,-40.8461\"/\u003e\n\u003cpolygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"501.3047,-37.7926 491.0114,-35.2827 497.4928,-43.6637 501.3047,-37.7926\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"575.8922\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eyes, missing\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 10 --\u003e\n\u003cg id=\"node9\" class=\"node\"\u003e\n\u003ctitle\u003e10\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"656.3922\" cy=\"-18\" rx=\"88.2844\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"656.3922\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eleaf=\u0026#45;0.0346354321\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 4\u0026#45;\u0026gt;10 --\u003e\n\u003cg id=\"edge8\" class=\"edge\"\u003e\n\u003ctitle\u003e4\u0026#45;\u0026gt;10\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#ff0000\" d=\"M610.4098,-86.9735C618.5754,-74.7252 629.5145,-58.3165 638.6745,-44.5766\"/\u003e\n\u003cpolygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"641.7551,-46.2653 644.3899,-36.0034 635.9307,-42.3824 641.7551,-46.2653\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"639.3922\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eno\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 11 --\u003e\n\u003cg id=\"node12\" class=\"node\"\u003e\n\u003ctitle\u003e11\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"851.3922\" cy=\"-18\" rx=\"88.2844\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"851.3922\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eleaf=\u0026#45;0.0259839185\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 5\u0026#45;\u0026gt;11 --\u003e\n\u003cg id=\"edge11\" class=\"edge\"\u003e\n\u003ctitle\u003e5\u0026#45;\u0026gt;11\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#0000ff\" d=\"M896.5817,-86.9735C888.5569,-74.7252 877.8064,-58.3165 868.8044,-44.5766\"/\u003e\n\u003cpolygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"871.5954,-42.4499 863.1875,-36.0034 865.7402,-46.2861 871.5954,-42.4499\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"918.8922\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eyes, missing\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 12 --\u003e\n\u003cg id=\"node13\" class=\"node\"\u003e\n\u003ctitle\u003e12\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"1041.3922\" cy=\"-18\" rx=\"83.3857\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"1041.3922\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eleaf=\u0026#45;0.118282638\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 5\u0026#45;\u0026gt;12 --\u003e\n\u003cg id=\"edge12\" class=\"edge\"\u003e\n\u003ctitle\u003e5\u0026#45;\u0026gt;12\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#ff0000\" d=\"M935.6276,-87.1843C956.1577,-73.7548 984.4666,-55.237 1006.6305,-40.7388\"/\u003e\n\u003cpolygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1008.6469,-43.6022 1015.0995,-35.199 1004.8149,-37.7442 1008.6469,-43.6022\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"991.3922\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eno\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 13 --\u003e\n\u003cg id=\"node14\" class=\"node\"\u003e\n\u003ctitle\u003e13\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"1227.3922\" cy=\"-18\" rx=\"85.2851\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"1227.3922\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eleaf=0.0639239252\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 6\u0026#45;\u0026gt;13 --\u003e\n\u003cg id=\"edge13\" class=\"edge\"\u003e\n\u003ctitle\u003e6\u0026#45;\u0026gt;13\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#0000ff\" d=\"M1227.3922,-86.9735C1227.3922,-75.1918 1227.3922,-59.5607 1227.3922,-46.1581\"/\u003e\n\u003cpolygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"1230.8923,-46.0033 1227.3922,-36.0034 1223.8923,-46.0034 1230.8923,-46.0033\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"1262.8922\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eyes, missing\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 14 --\u003e\n\u003cg id=\"node15\" class=\"node\"\u003e\n\u003ctitle\u003e14\u003c/title\u003e\n\u003cellipse fill=\"none\" stroke=\"#000000\" cx=\"1419.3922\" cy=\"-18\" rx=\"88.2844\" ry=\"18\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"1419.3922\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eleaf=\u0026#45;0.0461945944\u003c/text\u003e\n\u003c/g\u003e\n\u003c!-- 6\u0026#45;\u0026gt;14 --\u003e\n\u003cg id=\"edge14\" class=\"edge\"\u003e\n\u003ctitle\u003e6\u0026#45;\u0026gt;14\u003c/title\u003e\n\u003cpath fill=\"none\" stroke=\"#ff0000\" d=\"M1260.836,-89.8458C1292.0658,-75.6948 1338.9395,-54.4551 1373.6289,-38.7365\"/\u003e\n\u003cpolygon fill=\"#ff0000\" stroke=\"#ff0000\" points=\"1375.4029,-41.7753 1383.0668,-34.4599 1372.5137,-35.3993 1375.4029,-41.7753\"/\u003e\n\u003ctext text-anchor=\"middle\" x=\"1342.3922\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\"\u003eno\u003c/text\u003e\n\u003c/g\u003e\n\u003c/g\u003e\n\u003c/svg\u003e\n","text/plain":["\u003cgraphviz.dot.Digraph at 0x7fded9538c50\u003e"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["from xgboost import plot_tree, to_graphviz\n","\n","\n","# Plot the tree\n","\n","### BEGIN SOLUTION\n","to_graphviz(xgb, num_trees = 19)\n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{"id":"k8q56l8mwsJT"},"source":["#### Q1: Based on the tree plotted above, which of the following feature is a root node in the 20th tree?\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Choose from the drop box below."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"iRdTM9nUwsJV"},"outputs":[{"name":"stderr","output_type":"stream","text":["ERROR:root:File `'plot_tree_quiz.py'` not found.\n"]}],"source":["### RUN THIS CELL TO ANSWER\n","%run plot_tree_quiz.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_e2b1h8JwsJb"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-22-5d3943bf4c2c\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_tree_quiz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Points allocated : 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m### BEGIN HIDDEN TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_tree_quiz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'required_car_parking_spaces'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### END HIDDEN TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plot_tree_quiz' is not defined"]}],"source":["assert(plot_tree_quiz.value != None)\n","# Points allocated : 1\n","### BEGIN HIDDEN TESTS\n","assert(plot_tree_quiz.value == 'required_car_parking_spaces')\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"C0bjxiIhwsJg"},"source":["### Feature importance\n","\n","### Exercise 5: Plot the feature importance\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","XGBoost provides the `feature_importance()` method to plot the importance of each feature. Based on the feature_importance plot, you need to answer the quiz below.\n","\n","**Task:** \n","-  Plot the feature importance of the model `xgb`.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ed50WkR6wsJi","scrolled":false},"outputs":[],"source":["from xgboost import plot_importance\n","fig, ax = plt.subplots(figsize=(10,6), dpi=300)\n","None # plot_importance(.....)\n","### BEGIN SOLUTION\n","plot_importance(xgb, ax = ax, importance_type = 'gain')\n","### END SOLUTION\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"bf1yeatOwsJm"},"source":["#### Q2: Based on the gain, which of the following is the most important feature?\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Choose from the drop box below."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9FsVeR4uwsJr"},"outputs":[],"source":["### RUN THIS CELL TO ANSWER\n","%run plot_importance_quiz.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MZ9XNIl7wsJ0"},"outputs":[],"source":["assert(plot_importance_quiz.value != None)\n","# Points allocated: 1\n","### BEGIN HIDDEN TESTS\n","assert(plot_importance_quiz.value == 'deposit_type')\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"r4jBHfvEwsJ5"},"source":["### Parallelization\n","\n","### Exercise 6: Multithreading\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","As already discussed in the theoretical part, XGBoost is known for parallelization and distributed computing. Here we are going to instantiate XGBoost with its support for multithreading. You can refer to the documentation of XGBoost on how to set the number of threads to the number of cores.\n","\n","**Task:**  \n","- Instantiate a XGBClassifier() to variable `model` with __random_state__ set to RANDOM_STATE and set the number of threads to number of cores.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4fxzfOVawsJ6"},"outputs":[],"source":["model = None\n","### BEGIN SOLUTION\n","model = XGBClassifier(random_state = RANDOM_STATE, n_jobs = -1)\n","### END SOLUTION"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9ApKHxgqwsKA","scrolled":true},"outputs":[],"source":["### INTENTIONALLY LEFT BLANK\n","### BEGIN HIDDEN TESTS\n","assert model.n_jobs == -1, \"Set the number of threads to number of cores.\"\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"UPh-UJB7wsKF"},"source":["### Performance Monitoring and learning curve\n","\n","For performance monitoring, we define a function `learning_curve()` which plots the log loss for each boosting iteration for training and validation dataset. \n","\n","Note: Here, test data is used for validation, but it is good practice to have a separate validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pKJo8Fk3wsKF","scrolled":false},"outputs":[],"source":["def learning_curve(model, X_train, y_train, X_test, y_test):\n","    \"\"\"\n","    A function to plot the learning curve.\n","    \n","    Paramters:\n","    ---------\n","    model: object\n","           An object instantiated with XGBoost classifier\n","    X_train: array like\n","             Training features\n","    y_train: array like\n","             Training labels\n","    X_test: array like\n","            Validation features\n","    y_test: array like\n","            Validation labels\n","            \n","    Returns:\n","    --------\n","    None\n","    \n","            \n","    \"\"\"\n","    eval_set = [(X_train, y_train),(X_test, y_test)]\n","    model.fit(X_train, y_train, eval_metric = [\"logloss\"], eval_set = eval_set, verbose = False)\n","    print(\"F1 Score Train: \",f1_score(y_train, model.predict(X_train), average = 'weighted'))\n","    print(\"F1 Score Test: \",f1_score(y_test, model.predict(X_test), average = 'weighted'))\n","    results = model.evals_result()\n","    num_tree = len(results['validation_0']['logloss'])\n","    plt.figure(figsize = (8,8))\n","    plt.plot(range(0, num_tree), results['validation_0']['logloss'], label = 'Training')\n","    plt.plot(range(0, num_tree), results['validation_1']['logloss'], label = 'Validation')\n","    plt.legend()\n","    plt.xlabel(\"Number of trees\")\n","    plt.ylabel(\"Log loss\")\n","    plt.title(\"Learning Curve\")\n","    plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"C56MY88twsKI"},"source":["### Exercise 7: Learning Curve\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","A function `learning_curve()` is defined above. Use this function to plot the learning curve for the training and validation dataset. Here we will be using the test set for validation.\n","**Task:**  \n","- Instantiate a XGBClassifier() to variable `model` with __n_estimators__ set to 100 , __max_depth__ set to 4, and __random_state__ set to RANDOM_STATE.\n","-  Use the function `learning_curve()` to plot the learning curve of the model `xgb`. We have already instantiated `xgb` a few cells back.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7aq5FtPYwsKJ"},"outputs":[],"source":["model = None\n","# Plot learning curve\n","### BEGIN SOLUTION\n","model = XGBClassifier(n_estimators = 100, max_depth =4, random_state = RANDOM_STATE)\n","learning_curve(model, X_train, y_train, X_test, y_test)  \n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{"id":"inOMafAZwsKM"},"source":["#### Q3: Recalling evaluation results of random forest trained few cells above and analyzing the above learning curve shows that our xgboost model is  ____?\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Choose from the drop box below."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EqvwXBIpwsKN"},"outputs":[],"source":["### RUN THIS CELL TO ANSWER\n","%run is_overfitted.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Us8XpqEtwsKT"},"outputs":[],"source":["assert(is_overfitted.value != None)\n","### BEGIN HIDDEN TESTS\n","assert(is_overfitted.value == 'underfitted')\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"bfLb4QKawsKX"},"source":["### Exercise 8: Improving performance\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 1]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Based on your answer, if the model is overfitted, under fitted, or optimally fitted, you need to perform a few experiments and improve its performance. The test f1-score of the model should be above 89.00%\n","\n","Hint: If the model is overfitted, you can perform shrinkage, reduce the depth of the tree, apply regularization, etc. Similarly, if the model is under fitted, you can increase the number of iterations and the tree depth.\n","\n","**Task:**  \n","- Instantiate a XGBClassifier() to variable `model` with the parameters you think are suitable for improving performance.\n","- Note: The test f1 score of your model should be equal or above 0.8900 to get the marks.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-hgayJeYwsKY"},"outputs":[],"source":["model = None\n","### BEGIN SOLUTION\n","# xgb = XGBClassifier(n_estimators = 400, n_jobs = -1, max_depth = 15, gamma = 0.1, min_child_weight = 5, random_state = RANDOM_STATE)\n","model = XGBClassifier(n_estimators = 400, n_jobs = -1, max_depth = 15, random_state = RANDOM_STATE)\n","### END SOLUTION\n","model.fit(X_train, y_train)\n","pickle.dump(model, open(\"model.pickle.dat\", \"wb\"))\n","\n","print(\"Train f1_score:\", f1_score(y_train, model.predict(X_train), average = 'weighted'))\n","print(\"Test f1_score:\", f1_score(y_test, model.predict(X_test), average = 'weighted'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"KK6gIaq9wsKc"},"outputs":[],"source":["### INTENTIONALLY LEFT BLANK\n","### BEGIN HIDDEN TESTS\n","model = pickle.load(open(\"model.pickle.dat\", \"rb\"))\n","f1_score_hidden = f1_score(y_test, model.predict(X_test), average = 'weighted')\n","assert f1_score_hidden \u003e= 0.89, \"F1-score on test set is below 0.8900\"\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"2EPPp2jWwsKg"},"source":["### Model Tuning\n","\n","A function `tuning_curve()` is defined, which tunes the xgboost . Here `param_name` is the name of the parameter, and `param_range` is the corresponding range of the parameter's value. This function plot the log loss for different value of these parameters. The plot has a vertical line with a central dot corresponding to each value of the parameter.  The vertical length represents the standard deviation of log loss for three cross-fold validation. Similarly, the central dot represents the mean log loss for three cross-fold validation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eg_vu2BBwsKg"},"outputs":[],"source":["from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import StratifiedKFold\n","\n","\n","def tuning_curve(param_name, param_range):\n","    \"\"\"\n","    A function to perform hyperparameter tuning.\n","    \n","    A 3 fold stratified cross validation is performed for each value of parameter.\n","    \n","    \n","    Parameters:\n","    ----------\n","    param_name: str\n","                Name of the parameter on which to perform hyperparamter tuning.\n","    param_range: list\n","                 Range of parameter to perform grid search\n","                 \n","    Returns:\n","    -------\n","    None\n","    \"\"\"\n","    mean = []\n","    std = []\n","    for n in param_range:\n","        arg = dict()\n","        arg[param_name] = n\n","        model = XGBClassifier(random_state = RANDOM_STATE,n_jobs = -1,  **arg)\n","        skfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n","        scores = cross_validate(model, X_train, y_train, scoring = ['neg_log_loss'], cv = skfold)\n","        mean_temp = np.abs(scores['test_neg_log_loss']).mean()\n","        mean.append(mean_temp)\n","        std_temp = np.abs(scores['test_neg_log_loss']).std()/2.0\n","        std.append(std_temp)\n","    plt.errorbar(param_range, mean, std, fmt = 'o') \n","    plt.xlabel(\"{}\".format(param_name))\n","    plt.ylabel(\"{}\".format(\"Log loss\"))\n","    plt.title(\"Cross Validation Score\")\n","    plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"M46PQhAKwsKj"},"source":["### Exercise 9: Tuning L1-Regularization term.\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","A function `tuning_curve()` is defined above. Use this function to tune L1 regularization term in the range $[0, 0.4, 1, 5, 10]$\n","\n","**Task:**  \n","- Use function `tuning_curve()` to tune the parameter `reg_alpha` in the range $[0, 0.4, 1, 5, 10]$ and answer the following quiz.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"o_ES-JPNwsKl"},"outputs":[],"source":["None # Call function tuning_curve() to tune reg_alpha in the given range\n","\n","### BEGIN SOLUTION\n","tuning_curve(param_name = 'reg_alpha', param_range = [0, 0.4, 1, 5, 10])  \n","### END SOLUTION"]},{"cell_type":"markdown","metadata":{"id":"eciMTlsjwsKo"},"source":["#### Q4: From the above curve, which of the following value of reg_alpha yields the best performance?\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Choose from the drop box below.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"05rB4PBzwsKo"},"outputs":[],"source":["### RUN THIS CELL TO ANSWER\n","%run tuning_alpha.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YvRtF_WRwsKr"},"outputs":[],"source":["assert(tuning_alpha_quiz.value != None)\n","### BEGIN HIDDEN TESTS\n","assert(tuning_alpha_quiz.value == '1')\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"Yie7qnu3wsKv"},"source":["__Congratulation!!!!!!!!!!!!!__\n","\n","__You have completed level 1__"]},{"cell_type":"markdown","metadata":{"id":"IX6VJobpwsKw"},"source":["## Level 2+3\n","\n","## Learning Objective (Level2+Level 3)\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 6]\u003c/div\u003e\u003c/b\u003e\n","\n","- Implement Gradient Boosting Regressor from scratch.\n","\n","- Compare the performance of gradient boosting regressor implement from scratch with Sklearn's gradient boosting regressor.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"V5t25PcIwsKx"},"source":["### Dataset Description\n","\n","We will use a synthetic dataset for this part. A synthetic dataset is generated using Sklearn's `make_regression()` method.\n","\n","---\n","Number of Instances: 100\n","\n","Number of Attributes:4\n","\n","---\n","The features are labeled `x1`, `x2`,`x3`,`x4`, and the output value is labeled `target`.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"MDvsa8egwsKx","scrolled":true},"outputs":[],"source":["from sklearn.datasets import make_regression\n","\n","\n","RANDOM_STATE = 7\n","X, y = make_regression(n_samples=100, n_features=4, n_informative=3, bias = 2,noise=0.05, random_state = RANDOM_STATE)\n","df = pd.DataFrame(X, columns = ['x1', 'x2', 'x3', 'x4'])\n","df['target']= y\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"L9fe-DOjwsK1"},"source":["### Scatter plot"]},{"cell_type":"markdown","metadata":{"id":"gCJllXViwsK1"},"source":["If you would like, you could visualize the scatter plot of individual features with respect to the target variable. Moreover, if you like to understand better the distribution of the data, you can experiment yourself."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EPrD4CUZwsK3","scrolled":false},"outputs":[],"source":["# Perform experiment to understand data distribution if needed.\n","plt.scatter(X[:,0], y)\n","plt.ylabel(\"Output/independent variable\")\n","plt.xlabel(\"Input/dependet variable\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"HQxBrCMAwsK7"},"source":["### Train Test Split\n","As usual, we will keep 80% of the data for training and the rest for testing."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sHr2YzgbwsK8"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = RANDOM_STATE)"]},{"cell_type":"markdown","metadata":{"id":"OdD_9-8twsK_"},"source":["## Gradient Boosting Regressor from scratch\n","In this section, we will implement a gradient boosting regressor from scratch. Each base learner will be a decision tree. For this, we will use Sklearn's `DecisionTreeRegressor()` object.\n","\n","Here is a pseudo-code for gradient boosting regressor.\n","```\n","Algorithm:\n","```\n","\u003e 1. initialize $F_0= \\frac{1}{N}\\sum_{i=1}^N y_i$\n","2. for $t=1$ to $M$ do\n","3. \u003e calculate negative gradients $-g(\\mathbf{x_i})$; where $-g(\\mathbf{x_i})= -\\frac{\\partial L(y_i, F(\\mathbf{x_i}))}{\\partial F(\\mathbf{x_i})}\\bigg{|}_{F = F_{t-1}}$\n","4. \u003e fit a base-learner model $h$ to negative gradients $-g(\\mathbf{x_i})$\n","5. \u003e update the function: $F_t=F_{t-1} + \\alpha h(\\mathbf{x})$; where $\\alpha$ is a shrinkage\n","6. end for"]},{"cell_type":"markdown","metadata":{"id":"078dpGJLwsLA"},"source":["Below is a skeleton class for the gradient boosting regressor. We have already defined a constructor for initializing different attributes like `learning_rate`, `max_depth` of each tree, and `n_estimators` for the number of boosting iterations. The attribute `estimators` is a list of each trained base learner.\n","\n","### Exercise 10: Gradient Boosting Regressor from scratch\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 1+3+1]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","This exercise is divided into three different tasks. Through these three tasks, you will create a gradient boosting regressor.\n","\n","**Task 1: Computation of negative gradient** \n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 1]\u003c/div\u003e\u003c/b\u003e\n","\n","We have defined a static method `negative_gradient` which should return the negative gradient when actual label $y$ and predicted label $\\hat{y}$ are given. You need to complete this function.\n","\n","-  Your task is to assign the negative gradient the the variable `grad`. Suppose we are using the following loss function $$L(y,\\hat{y})= \\frac{1}{2}(y-\\hat{y})^2$$ \n","where, $y$ is the actual label and $\\hat{y}$ is the predicted label.\n","\n","\n","**Task 2: Fit the model** \n","\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 3]\u003c/div\u003e\u003c/b\u003e\n","\n","\n","In this task, we are going to fit our model with the training dataset. We have defined a function `fit(X,y)` in the class `Gradient_Boosting_Regressor` where, X is the training features, and y is the training label. As already discussed in the reading material, the first prediction is the average of output label. Here we have defined two attributes, `average` and `base_prediction`. `base_prediction` is a vector of average value with a length equal to the number of instances in the training data. \n","\n","\n","- Compute the negative_gradient using the above defined function and put it in the variable `pseduo_residual`.\n","- Instantiate a decision tree regressor(from sklearn) on variable `tree` setting `max_depth` to the variable provided in the class constructor and setting `random_state` to RANDOM_STATE.\n","- Fit the tree on input X and pseudo_residual as a target.\n","- Update `base_prediction` with the prediction of the current tree. Note: The prediction of each tree should be downscaled by shrinkage. Please replace 0 with your own code.\n","\n","**Task 3: Prediction by model** \n","\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 1]\u003c/div\u003e\u003c/b\u003e\n","\n","\n","In this exercise, we are going to make a prediction based on the input data. We have defined a function `predict(X)` in the class `Gradient_Boosting_Regressor` where, X is a feature for which we want to make a prediction. Here we have initialized the variable `predictions` by the average value of the training label. We want to return the final prediction made by the model.\n","\n","\n","- The average prediction is already assigned to the variable `predictions`. Your task is to add the predictions made by each estimator to the variable `predictions`. Please replace 0 with your code.\n","\n","\n","The last method, `staged_predict()` is a generator that returns the prediction for each boosting iterations."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NOP9uMawwsLA"},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor\n","\n","class Gradient_Boosting_Regressor:\n","    \"\"\"\n","    Gradient boosting for regression.\n","    \n","    This implementation uses a mean square error loss function.\n","    \n","    Parameters:\n","    ----------\n","    learning_rate: int\n","                   Learning rate or shrinkage parameter (the default is 0.1)\n","    max_depth: int\n","               Maximum allowed depth for each tree (the default value is 4)\n","    n_estimators: int\n","                  The total number of boosting operations (the default value is 5)  \n","                   \n","    \"\"\"\n","    def __init__(self, learning_rate = 0.1, max_depth = 3, n_estimators = 5):\n","        self.learning_rate = learning_rate\n","        self.max_depth = max_depth\n","        self.n_estimators = n_estimators\n","        self.estimators = []\n","        \n","        \n","    @staticmethod\n","    def negative_gradient(y, y_pred):\n","        \"\"\"Compute and return the negative gradient. \"\"\"\n","        grad = None\n","        ### BEGIN SOLUTION\n","        grad = y-y_pred\n","        ### END SOLUTION\n","        return grad\n","    \n","    \n","    def fit(self, X, y):\n","        \"\"\"Fit the model on data X and y\"\"\"\n","        self.average = np.mean(y)\n","        self.base_prediction = np.array([np.mean(y)]*len(y))\n","        \n","        for estimators in range(self.n_estimators):\n","            pseudo_residuals = None\n","            tree = None \n","            None # tree.fit(...)\n","            self.base_prediction += 0 # None ########### WHAT IS THE USE OF THIS LINE?\n","            ### BEGIN SOLUTION\n","            pseudo_residuals = self.negative_gradient(y, self.base_prediction)\n","            tree = DecisionTreeRegressor(max_depth = self.max_depth, random_state = 7)\n","            tree.fit(X, pseudo_residuals)\n","            self.base_prediction += self.learning_rate*tree.predict(X)            \n","            ### END SOLUTION\n","            self.estimators.append(tree)\n","            \n","            \n","    def predict(self, X):\n","        \"\"\"Make prediction by the model on data X.\"\"\"\n","        predictions = np.array([self.average]*X.shape[0])\n","        for estimator in self.estimators:\n","            predictions += 0 # None\n","            ### BEGIN SOLUTION\n","            predictions += self.learning_rate*estimator.predict(X)\n","            ### END SOLUTION\n","        return predictions\n","    \n","    \n","    def staged_predict(self, X):\n","        \"\"\"A generator which returns the prediction at each boosting iteration.\"\"\"\n","        predictions = np.array([self.average]*X.shape[0])\n","        \n","        for estimator in self.estimators:\n","            predictions += self.learning_rate*estimator.predict(X)\n","            yield predictions\n","\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Y9jBuEOTwsLC"},"outputs":[],"source":["assert Gradient_Boosting_Regressor().negative_gradient(y_train, y_train+1) is not None\n","### BEGIN HIDDEN TESTS\n","y_hidden_true = np.array([1.4, 2.0, 3.3, 9.1, 3.4])\n","y_hidden_pred = np.array([0.0, 1.1, 2.4, 4.7, 8.4])\n","gradient_hidden = (y_hidden_true - y_hidden_pred)\n","gradient_hidden_by_student = Gradient_Boosting_Regressor().negative_gradient(y_hidden_true, y_hidden_pred)\n","np.testing.assert_equal(gradient_hidden, gradient_hidden_by_student, err_msg = \"Please check the function negative_gradient().\")\n","### END HIDDEN TESTS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"pcndEFghwsLI"},"outputs":[],"source":["model = Gradient_Boosting_Regressor()\n","model.fit(X_train, y_train)\n","assert not np.array_equal(model.predict(X_train), np.array([np.mean(y_train)]*len(y_train))), \"Make sure you have implemented the code for fit and predict methods.\"\n","### BEGIN HIDDEN TESTS\n","\n","class Gradient_Boosting_Regressor:\n","    \"\"\"\n","    Gradient boosting for regression.\n","    \n","    This implementation uses mean square error loss function.\n","    \n","    Parameters:\n","    ----------\n","    learning_rate: int\n","                   Learning rate or shrinkage parameter (the default is 0.1)\n","    max_depth: int\n","               Maximum allowed depth for each tree (the default value is 4)\n","    n_estimators: int\n","                  The total number of boosting operations (the default value is 5)  \n","                   \n","    \"\"\"\n","    def __init__(self, learning_rate =0.1, max_depth = 3, n_estimators = 5):\n","        self.learning_rate = learning_rate\n","        self.max_depth = max_depth\n","        self.n_estimators = n_estimators\n","        self.estimators = []\n","        \n","        \n","    @staticmethod\n","    def negative_gradient(y, y_pred):\n","        \"\"\"Compute and returns the negative gradient. \"\"\"\n","        grad = y-y_pred\n","        return grad\n","    \n","    \n","    def fit(self, X, y):\n","        \"\"\"Fit the model\"\"\"\n","        self.average = np.mean(y)\n","        self.base_prediction = np.array([np.mean(y)]*len(y))\n","        \n","        for estimators in range(self.n_estimators):\n","            pseudo_residuals = self.negative_gradient(y, self.base_prediction)\n","            \n","            tree = DecisionTreeRegressor(max_depth = self.max_depth, random_state = 7)\n","            tree.fit(X, pseudo_residuals)\n","            self.base_prediction += self.learning_rate*tree.predict(X)\n","            self.estimators.append(tree)\n","            \n","            \n","    def predict(self, X):\n","        \"\"\"Make prediction by the model for input data X.\"\"\"\n","        predictions = np.array([self.average]*X.shape[0])\n","        \n","        for estimator in self.estimators:\n","            predictions += self.learning_rate*estimator.predict(X)\n","        return predictions\n","    \n","    \n","    def staged_predict(self, X):\n","        \"\"\"A generator which returns the prediction at each boosting iteration.\"\"\"\n","        predictions = np.array([self.average]*X.shape[0])\n","        \n","        for estimator in self.estimators:\n","            predictions += self.learning_rate*estimator.predict(X)\n","            yield predictions\n","\n","teacher = Gradient_Boosting_RegressorT()\n","student = Gradient_Boosting_Regressor()\n","teacher.fit(X_train[:20, :], y_train[:20])\n","teacher_prediction_hidden = teacher.predict(X_train[:20, :])\n","\n","student.fit(X_train[:20, :], y_train[:20])\n","student_prediction_hidden = student.predict(X_train[:20, :])\n","\n","# np.testing.assert_almost_equal(teacher_prediction_hidden, student_prediction_hidden, decimal = 3,  err_msg = \"Please check either fit or predict method\" )\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"lZQXk1LKwsLK"},"source":["## Evaluation and Comparision\n","In this and coming sections, we will first evaluate the gradient boosting regressor that we just built from scratch and then compare it with the Sklearn's gradient boosting regressor."]},{"cell_type":"markdown","metadata":{"id":"6lBICO5cwsLL"},"source":["Let's see how our model has performed."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eEDtuZTewsLM","scrolled":true},"outputs":[],"source":["from sklearn.metrics import r2_score\n","\n","custom_gbm = Gradient_Boosting_Regressor(learning_rate = 0.2, max_depth = 3, n_estimators = 4)\n","custom_gbm.fit(X_train, y_train)\n","\n","\n","print(\"r2_score:\", r2_score(y_test, custom_gbm.predict(X_test)))"]},{"cell_type":"markdown","metadata":{"id":"beLuCubewsLR"},"source":["### Visualization\n","Let's see if the prediction gets improved with the added estimators. Here we will plot the actual and predicted target value."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"unyAB9CRwsLS","scrolled":false},"outputs":[],"source":["fig, ax = plt.subplots(1,4, figsize = (20,4.5), sharex = True)\n","fig.suptitle(\"Prediction made by our custom gradient boosting regressor\")\n","for i, pred in enumerate(custom_gbm.staged_predict(X_test)):\n","    ax[i].scatter(y_test, pred, marker = 'o')\n","    ax[i].set_title(\"n_estimators={}; r2_score={:04.2f}\".format(i+1, r2_score(y_test, pred)))\n","    ax[i].set_xlabel(\"Actual value\")\n","    ax[i].set_ylabel(\"Predicted value\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"a28anUbpwsLV"},"source":["#### Q5: With our custom gradient boosting regressor, the prediction has ______ with boosting iteration?\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Choose from the drop box below to fill in the blank."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"oQv2PyUWwsLV","scrolled":true},"outputs":[],"source":["### RUN THIS CELL TO ANSWER\n","%run custom_performance.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"39wF8tIVwsLa"},"outputs":[],"source":["assert(custom_performance.value != None)\n","\n","### BEGIN HIDDEN TESTS\n","assert(custom_performance.value == 'improved')\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"lOwaWEnOwsLf"},"source":["### Gradient Boosting Regressor in sklearn\n","Let's see how our model compared with the gradient boosting regressor in sklearn.\n","\n","### Exercise 11: Training Sklearn's GradientBoostingRegressor\n","\n","---\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[POINTS: 1]\u003c/div\u003e\u003c/b\u003e\n","\n","In this exercise, we are going to train Sklearn's GradientBoostingRegressor.\n","\n","**Task:** \n","- Create an object `gbm` of the `GradientBoostingRegressor` class setting criterion to `mse`, n_estimators to 4, max_depth to 3, learning_rate to 0.2 and random_state to RANDOM_STATE.\n","- Fit the object on the training set `X_train`, and `y_train`.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_se8m4-qwsLf"},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingRegressor\n","\n","gbm = None\n","# Fit the model \n","### BEGIN SOLUTION\n","gbm = GradientBoostingRegressor(criterion = 'mse', n_estimators = 4, max_depth = 3, learning_rate = 0.2, random_state = 7)\n","gbm.fit(X_train, y_train)\n","\n","### END SOLTUION\n","print(\"r2_score: \", r2_score(y_test, gbm.predict(X_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5P9ZkU5TwsLl"},"outputs":[],"source":["assert gbm is not None\n","### BEGIN HIDDEN TESTS\n","from sklearn.exceptions import NotFittedError\n","\n","\n","assert gbm.criterion == 'mse', \"Please set the criterion to mse\"\n","assert gbm.n_estimators == 4, \"Please set the number of estimators to 4\"\n","assert gbm.learning_rate ==0.2, \"Please set the learning rate to 0.2\"\n","assert gbm.random_state == RANDOM_STATE, \"Please set the random state to RANDOM_STATE\"\n","\n","try:\n","    gbm.predict(X_test)\n","except NotFittedError as e:\n","    raise \"Model is not fitted\"\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"FNI07SztwsLq"},"source":["### Visualization\n","Let's visualize how the prediction made by Sklearn's gradient boosting regressor looks."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZN1qS2i1wsLq","scrolled":true},"outputs":[],"source":["fig, ax = plt.subplots(1,4, figsize = (20,5), sharex = True, sharey=True)\n","fig.suptitle(\"Prediction made by sklearn's gradient boosting regressor\")\n","for i, pred in enumerate(gbm.staged_predict(X_test)):\n","    ax[i].scatter(y_test, pred, marker = 'o')\n","    ax[i].set_title(\"n_estimators={}; r2_score={:04.2f}\".format(i+1, r2_score(y_test, pred)))\n","    ax[i].set_xlabel(\"Actual value\")\n","    ax[i].set_ylabel(\"Predicted value\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"aQNwznniwsLt"},"source":["#### Q6: Based on the above two plots, the performance of Sklearn's gradient boosting regressor is ______ our custom gradient boosting regressor?\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Choose from the drop box below to fill in the blank."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"h6-7FqRhwsLu"},"outputs":[],"source":["### RUN THIS CELL TO ANSWER\n","%run performance_compare1.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JGF7fuyawsL4"},"outputs":[],"source":["assert(performance_compare1.value != None)\n","### BEGIN HIDDEN TESTS\n","assert(performance_compare1.value == 'same as')\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"bv3aMhnXwsL7"},"source":["### Loss vs. boosting iterations\n","We will plot the value of mse loss at different iterations to visualize how the model's performance has improved. The function `learning_curve()` plots the mse of training and test data at each boosting iteration."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IMxRSx_CwsL8"},"outputs":[],"source":["from sklearn.metrics import mean_squared_error as mse\n","\n","\n","def learning_curve(clf):\n","    train_mse = []\n","    test_mse = []\n","    for pred in clf.staged_predict(X_train):\n","        train_mse.append(mse(y_train, pred))\n","    for pred in clf.staged_predict(X_test):\n","        test_mse.append(mse(y_test, pred))\n","    plt.plot(np.arange(clf.n_estimators)+1, train_mse, 'r', label= \"Training\")\n","    plt.plot(np.arange(clf.n_estimators)+1, test_mse, 'b', label = \"Testing\")\n","    plt.xlabel(\"Iterations\")\n","    plt.ylabel(\"MSE loss\")\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bKa9EcY0wsL-"},"outputs":[],"source":["custom_clf = Gradient_Boosting_Regressor(n_estimators = 100, max_depth = 1, learning_rate = 0.1)\n","custom_clf.fit(X_train, y_train)\n","learning_curve(custom_clf)\n","print(\"MSE:\" ,mse(y_test, custom_clf.predict(X_test)))\n","print(\"r2_score\" ,r2_score(y_test, custom_clf.predict(X_test)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Yx8n8ElVwsMC"},"outputs":[],"source":["clf = GradientBoostingRegressor(n_estimators = 100, max_depth = 1, learning_rate = 0.1, criterion = 'mse')\n","clf.fit(X_train, y_train)\n","learning_curve(clf)\n","print(\"MSE:\", mse(y_test, clf.predict(X_test)))\n","print(\"r2_score\", r2_score(y_test, clf.predict(X_test)))"]},{"cell_type":"markdown","metadata":{"id":"v9EZ-Z1MwsMF"},"source":["#### Q7: Based on the learning curve, the performance of Sklearn's gradient boosting regressor is ______ our custom gradient boosting regressor?\n","\u003cb\u003e\u003cdiv style=\"text-align: right\"\u003e[UNGRADED]\u003c/div\u003e\u003c/b\u003e\n","\n","---\n","Choose from the drop box below to fill in the blank."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"46qOOEiywsMF"},"outputs":[],"source":["### RUN THIS CELL TO ANSWER\n","%run performance_compare2.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_YBheC4rwsMH"},"outputs":[],"source":["assert(performance_compare2.value != None)\n","### BEGIN HIDDEN TESTS\n","assert(performance_compare2.value == 'same as')\n","### END HIDDEN TESTS"]},{"cell_type":"markdown","metadata":{"id":"O7Pq0ki3wsMJ"},"source":["__Congratulation!!!!!!!!!!!!!__\n","\n","__You have completed the assignment__"]}],"metadata":{"colab":{"collapsed_sections":["M46PQhAKwsKj","eciMTlsjwsKo","beLuCubewsLR","a28anUbpwsLV","lOwaWEnOwsLf","FNI07SztwsLq","aQNwznniwsLt","bv3aMhnXwsL7","v9EZ-Z1MwsMF"],"name":"Assignment - Ensemble methods2.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"nbformat":4,"nbformat_minor":0}